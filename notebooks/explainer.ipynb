{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "## What is your dataset?\n",
    "We have chosen this dataset in order to investigate the patterns of fire incidents, and since London Fire Brigade in one of the largest and most busy fire departments in the globe, we figured this would be a great place to start.\n",
    "The dataset covers the years 2013, 2014 and 2015, as well as the first quarter of 2016.\n",
    "\n",
    "We shifted to this project from our previous since we found that the data was corrupted and our preliminary analysis could not find anything worth discussing. \n",
    "\n",
    "## Why did you choose this/these particular dataset(s)?\n",
    "The Motivation for this dataset was the fact that many people die in fires every single year. One team member has even lost a relative in a fire. \n",
    "\n",
    "\n",
    "## What was your goal for the end user's experience?\n",
    "To present the data in a beautiful and explaining way such that the user leaves the site enlightened.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic stats. Let's understand the dataset better\n",
    "\n",
    "## Write about your choices in data cleaning and preprocessing\n",
    "The data was very clean itself. One of the things that we did not like though, was the Easting/Northing format for the locations. We are used to Latitude/longitude, and if we very to use them in D3.js, we would have to convert. \n",
    "The conversion was done using the UTM package in python.\n",
    "\n",
    "We also did some initial processing with the data stamps, since they for one reason used the roman numbers format for the months. Such that 1.1.2013 would be 1.I.2013 instead. This was done with a simple conversion dictionary. \n",
    "\n",
    "We can some light scripts on the data in order to answers some very basic questions like whether there was an obvious pattern in with months/day/time of day the incidents occurred. This can be seen on the site. \n",
    "\n",
    "## Write a short section that discusses the dataset stats (here you can recycle the work you did for Project Assignment A)\n",
    "\n",
    "We shifted to this project from our previous and thus can't recycle from project A. \n",
    "\n",
    "The set is made of 26 columns/parameters that we can put to the test, including:\n",
    "\n",
    "* Time \n",
    "* Date\n",
    "* Location\n",
    "* Type of incident\n",
    "* Property type\n",
    "* Easting/northing location pointer\n",
    "\n",
    "## Theory. Which theoretical tools did you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe which machine learning tools you use and why the tools you've chosen are right for the problem you're solving.\n",
    "\n",
    "Based on our data we decided to go with <b>k-Nearest Neighbours</b> and <b>k-Means</b>.\n",
    "\n",
    "\n",
    "## Talk about your model selection. How did you split the data in to test/training. Did you use cross validation?\n",
    "\n",
    "### k-Nearest Neighbours\n",
    "A classification method kNN was used for predicting whether an incident call is real fire or not. The reason for using this model was having many features of an incident such as time or the week day of call. As labels we used obviously values either fire or not fire.\n",
    "\n",
    "### k-Means\n",
    "A clustering method k-Means was used to find the optimal positions of fire stations when we have a limited number which we can build. We have found k-Means as a perfect method for solving this task because it is unsupervised learning method. So the only information we provided was latitude and longitude. \n",
    "\n",
    "### Splitting data\n",
    "In both cases the data had been splitted to 80% of training and 20% for tests.\n",
    "\n",
    "## Explain the model performance. How did you measure it? Are your results what you expected?\n",
    "\n",
    "### k-Nearest Neighbours\n",
    "We used sklearn metrics for measuring the precision and recall.\n",
    "* 1 - Fire\n",
    "    * Precision 0.45%\n",
    "    * Recall 0.18\n",
    "* 0 - Not fire\n",
    "    * Precision 0.78%\n",
    "    * Recall 0.93\n",
    "    \n",
    "Results are unexpected both for fire and not fire. We were assuming we would get better in predicting a fire. But pretty much quite good at predicting a non fire incident.\n",
    "\n",
    "### k-Means\n",
    "\n",
    "We did not do any measurements here because the goal was creating just clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations\n",
    "## Explain the visualizations you've chosen.\n",
    "\n",
    "We have chosed:\n",
    "* Barcharts for showing data distribution through out the year/month/day\n",
    "* A map with clusters so users can see the optimal places of fire stations \n",
    " \n",
    "## Why are they right for the story you want to tell?\n",
    "\n",
    "Chosen visualizations are pretty descriptive they dont require that much time to understand.\n",
    "* In barchats one can easily spot trends \n",
    "* Maps are exciting to look at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion. Think critically about your creation\n",
    "\n",
    "## What went well?,\n",
    "The machine learning part went pretty well and once we had a better dataset, everything became a lot easier. \n",
    "The collaboration also went well since all team members were experienced with git and seamless code collaboration went smooth and without conflicts. \n",
    "\n",
    "## What is still missing? What could be improved?, Why?\n",
    "\n",
    "We would have loved to have better, stronger, deeper visualisations of the data, but the time was snappy due to the switch of the dataset. It would be also interesting to combine fire data with estates in different neighbourhoods of London and investigate whether there is any corelation between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
